# InventraAI

## Overview

**InventraAI** is a no-code machine learning platform designed to simplify the end-to-end ML workflow for **structured, time-series, and image data**. The platform enables users to upload datasets, automatically train predictive models, and generate insights and predictions **without writing any machine learning code**.

InventraAI follows a **rule-based AutoML approach**, where the system automatically performs data profiling, preprocessing, model selection, training, evaluation, and explainability. Instead of deploying models as external services, predictions are executed internally and displayed directly through an interactive user interface, keeping the system **simple, efficient, and easy to use**.

The platform is built entirely on **open-source technologies**, including **Streamlit** for the no-code interface, **Pandas and scikit-learn** for data processing and model training, and **MinIO** for scalable object storage of datasets, models, and artifacts. InventraAI is optimized for **educational use, rapid prototyping, and small-to-medium scale analytics**, while being architecturally ready to scale to distributed systems in future iterations.

---

## Key Highlights

* ğŸš€ **No-code, user-friendly ML workflow**
* ğŸ“Š **Supports tabular (CSV/Excel), time-series, and image datasets**
* âš¡ **8 AI Agents** for comprehensive automation
* âš™ï¸ **Automated data profiling, preprocessing, and model training**
* ğŸ“ˆ **Built-in model evaluation and explainability**
* ğŸ§© **Open-source, lightweight, and scalable-by-design**

---

# ğŸ—ï¸ System Architecture (React + Flask + Streamlit + MinIO)

## High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              User Browser                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚               â”‚
                â”‚               â”‚
                â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     React Frontend     â”‚  â”‚    Streamlit Frontend  â”‚
â”‚   (Main Application)   â”‚  â”‚   (Prediction & ML UI) â”‚
â”‚                        â”‚  â”‚                        â”‚
â”‚ â€¢ Login / Dashboard    â”‚  â”‚ â€¢ Training progress    â”‚
â”‚ â€¢ Dataset management   â”‚  â”‚ â€¢ Predictions          â”‚
â”‚ â€¢ Job history          â”‚  â”‚ â€¢ Charts & insights    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚ REST API                  â”‚ REST / Python
                â–¼                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Flask Backend                 â”‚
â”‚          (Core Orchestrator API)           â”‚
â”‚                                            â”‚
â”‚ â€¢ Auth & user management                   â”‚
â”‚ â€¢ Dataset registration                    â”‚
â”‚ â€¢ AutoML workflow control                 â”‚
â”‚ â€¢ Prediction orchestration                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚               â”‚
                â”‚               â”‚
                â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      PostgreSQL        â”‚  â”‚        MinIO            â”‚
â”‚   (Metadata Store)    â”‚  â”‚  (Object Storage)       â”‚
â”‚                        â”‚  â”‚                        â”‚
â”‚ â€¢ Users                â”‚  â”‚ â€¢ Raw datasets         â”‚
â”‚ â€¢ Experiments          â”‚  â”‚ â€¢ Processed data       â”‚
â”‚ â€¢ Job status           â”‚  â”‚ â€¢ Configs              â”‚
â”‚ â€¢ Configs              â”‚  â”‚ â€¢ Pipelines            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â€¢ Metrics & artifacts  â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


```


# ğŸ”„ Flow Summary

```
React UI
   â†“
Flask API
   â†“
MinIO (store data)
   â†“
Pandas AutoML
   â†“
Model + Artifacts â†’ MinIO
   â†“
Streamlit UI
   â†“
Predictions in Browser
```

---

# ğŸš€ Getting Started

## Prerequisites

- **Python 3.10+**
- **Node.js 18+**
- **Docker & Docker Compose** (for database and storage)
- **Git**

---

## ğŸ“¦ Installation

### 1. Clone the Repository

```bash
git clone https://github.com/bharat3214/InventraAI.git
cd InventraAI
```

### 2. Set Up Environment Variables

```bash
cp .env.example .env
# Edit .env with your configuration if needed
```

---

## ğŸ³ Running with Docker (Recommended)

### Start All Services

```bash
# Start all infrastructure + services
docker-compose up --build

# Or start in background
docker-compose up -d --build
```

**Access Points:**
- ğŸŒ **Frontend (React)**: http://localhost:3000
- ğŸ”Œ **Backend API**: http://localhost:5000
- ğŸ“Š **Streamlit App**: http://localhost:8501
- ğŸ’¾ **MinIO Console**: http://localhost:9001 (admin: minioadmin/minioadmin)

### Stop Services

```bash
docker-compose down
```

---

## ğŸ› ï¸ Running Locally (Development)

### Step 1: Start Infrastructure Only

```bash
docker-compose up -d postgres redis minio
```

### Step 2: Backend Setup

```bash
cd backend

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Initialize database
python migrations.py init

# (Optional) Seed with demo data
python migrations.py seed

# Run backend server
python run.py
```

Backend runs at: http://localhost:5000

### Step 3: Frontend Setup

```bash
cd frontend

# Install dependencies
npm install

# Run development server
npm run dev
```

Frontend runs at: http://localhost:3000

### Step 4: Streamlit App (Optional)

```bash
cd streamlit_app

# Install dependencies
pip install -r requirements.txt

# Run Streamlit
streamlit run app.py
```

Streamlit runs at: http://localhost:8501

### Step 5: Celery Worker (For Background Training)

```bash
cd backend

# In a new terminal
celery -A app.celery_app worker --loglevel=info
```

---

## ğŸ§ª Running Tests

```bash
# Install test dependencies
pip install pytest

# Run all tests
pytest

# Run with coverage
pytest --cov=.
```

---

## ğŸ“ Project Structure

```
InventraAI/
â”œâ”€â”€ backend/                 # Flask API Server
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ models/         # Database models
â”‚   â”‚   â”œâ”€â”€ routes/         # API endpoints
â”‚   â”‚   â”œâ”€â”€ services/       # Business logic
â”‚   â”‚   â””â”€â”€ tasks/          # Celery background tasks
â”‚   â”œâ”€â”€ migrations.py       # Database management
â”‚   â””â”€â”€ run.py              # Entry point
â”‚
â”œâ”€â”€ frontend/               # React Dashboard
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ pages/          # Page components
â”‚   â”‚   â”œâ”€â”€ components/     # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ services/       # API client
â”‚   â”‚   â””â”€â”€ store/          # State management
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ ml_engine/              # AutoML Core
â”‚   â”œâ”€â”€ automl/
â”‚   â”‚   â”œâ”€â”€ tabular/        # Classification, Regression, Clustering
â”‚   â”‚   â”œâ”€â”€ timeseries/     # ARIMA, Prophet, LSTM
â”‚   â”‚   â””â”€â”€ vision/         # Image Classification
â”‚   â”œâ”€â”€ preprocessing/      # Data preprocessors
â”‚   â”œâ”€â”€ explainability/     # SHAP explanations
â”‚   â””â”€â”€ packaging/          # Model packaging
â”‚
â”œâ”€â”€ streamlit_app/          # Prediction UI
â”œâ”€â”€ docker/                 # Dockerfiles
â”œâ”€â”€ tests/                  # Unit & Integration tests
â””â”€â”€ docker-compose.yml      # Full stack orchestration
```

---

## ğŸ”‘ Demo Credentials

After running `python migrations.py seed`:

```
Email: demo@inventra.ai
Password: demo123
```

---

## ğŸ›¡ï¸ Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `FLASK_ENV` | Environment mode | development |
| `DATABASE_URL` | PostgreSQL connection | postgresql://postgres:postgres@localhost:5432/inventra_ai |
| `REDIS_URL` | Redis connection | redis://localhost:6379/0 |
| `MINIO_ENDPOINT` | MinIO server | localhost:9000 |
| `MINIO_ACCESS_KEY` | MinIO access key | minioadmin |
| `MINIO_SECRET_KEY` | MinIO secret key | minioadmin |
| `JWT_SECRET_KEY` | JWT signing key | your-jwt-secret-key |

---

## ğŸ“ API Documentation

### Authentication
- `POST /api/auth/register` - Create new account
- `POST /api/auth/login` - Login & get token
- `GET /api/auth/me` - Get current user

### Datasets
- `GET /api/datasets` - List all datasets
- `POST /api/datasets/upload` - Upload dataset
- `GET /api/datasets/:id` - Get dataset details

### Training
- `POST /api/training/start` - Start training job
- `GET /api/training/:id/status` - Get job status

### Models
- `GET /api/models` - List trained models
- `GET /api/models/:id/schema` - Get prediction form schema

### Predictions
- `POST /api/predict/:modelId` - Make prediction
- `POST /api/predict/:modelId/explain` - Get explanation

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License.

---

## ğŸ™‹ Support

For issues or questions, please open an issue on GitHub.

#   H a c k a t h o n - A H  
 